{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single federated model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvRgFiYt3Ydt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c64de9ff-0e89-4a8f-b57b-8e59fc3f47c0"
      },
      "source": [
        "pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 41.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 40.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 33.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 69.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 52.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 41.8MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYaVgXWP-NvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install --upgrade tensorflow_federated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McS2mDMF3mCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install --quiet tensorflow==2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS7OhTaH4AH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "# TODO(b/148678573,b/148685415): must use the ReferenceExecutor because it\n",
        "# supports unbounded references and tff.sequence_* intrinsics.\n",
        "tff.framework.set_default_executor(tff.framework.ReferenceExecutor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7ccTzo84GBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd5e1f44-c398-4be5-95c5-6f2833be5a9d"
      },
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8foHwobHIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c7532157-3636-4e0f-f63b-ac8dab914092"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dJq9Om5YACZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "all_buildings = pd.read_csv('/content/drive/My Drive/Dataset/building meta data.csv')\n",
        "zipfile = np.load('/content/drive/My Drive/Dataset/Office_NewYork_1000-3000_6-10_7.npz', allow_pickle=True)\n",
        "\n",
        "Building_data = zipfile['data']\n",
        "Building_data_norm = zipfile['data_norm']\n",
        "Building_names = zipfile['name']\n",
        "List_of_names = pd.Series(Building_names).unique()\n",
        "\n",
        "NUM_EXAMPLES_PER_USER = 10000\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "EC_min = np.min(Building_data[:,-1])\n",
        "EC_max = np.max(Building_data[:,-1])\n",
        "EC_mean = np.mean(Building_data[:,-1])\n",
        "\n",
        "def get_data_for_name(Data, Names, name):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, n in enumerate(Names) if n == name]\n",
        "\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i+BATCH_SIZE]\n",
        "    output_sequence.append({'x':np.array([Data[i,:-1] for i in batch_samples], dtype=np.float32),\n",
        "                'y':np.array([Data[i,-1] for i in batch_samples], dtype=np.float32)})\n",
        "  return output_sequence\n",
        "\n",
        "def get_label_for_name(Data, Names, name):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, n in enumerate(Names) if n == name]\n",
        "\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i+BATCH_SIZE]\n",
        "    output_sequence.append({'y':np.array([Data[i,-1] for i in batch_samples], dtype=np.float32)})\n",
        "  return output_sequence\n",
        "\n",
        "\n",
        "federated_train_data = [get_data_for_name(Building_data_norm, Building_names, name) for name in List_of_names[:-2]]\n",
        "\n",
        "federated_valid_data = [get_data_for_name(Building_data_norm, Building_names, name) for name in List_of_names[-2:-1]]\n",
        "\n",
        "local_data = [get_data_for_name(Building_data_norm, Building_names, name) for name in List_of_names[-1:]]\n",
        "\n",
        "local_train_data = local_data[0][:2]\n",
        "\n",
        "local_test_data = local_data[0][-2:]\n",
        "\n",
        "Label_test_data = [get_label_for_name(Building_data, Building_names, name) for name in List_of_names[-1:]][0][-2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCsQIocP4lFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "132b922d-2866-4b35-a357-a3c5a4ece58d"
      },
      "source": [
        "federated_train_data[4][-1]['y']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.20318568, 0.2237399 , 0.2491381 , 0.24848352, 0.24521056,\n",
              "       0.25214925, 0.25699323, 0.25450578, 0.2609208 , 0.24573424,\n",
              "       0.2229544 , 0.21640848, 0.22125246, 0.22622737, 0.2264892 ,\n",
              "       0.22544184, 0.23264237, 0.23198777, 0.23238054, 0.23473707,\n",
              "       0.23656993, 0.23146412, 0.24442504, 0.24861443, 0.30504036,\n",
              "       0.28775913, 0.3495527 , 0.34470868, 0.35897884, 0.36041892,\n",
              "       0.39341044, 0.3432686 , 0.35766965, 0.37665287, 0.29456687,\n",
              "       0.25345844, 0.23997381, 0.23251146, 0.23552257, 0.23146412,\n",
              "       0.23355879, 0.23761728, 0.23958106, 0.23997381, 0.24010472,\n",
              "       0.24953088, 0.24874537, 0.25031638, 0.28998473, 0.3221907 ,\n",
              "       0.37612915, 0.40820426, 0.381235  , 0.35662228, 0.3648702 ,\n",
              "       0.37586734, 0.35112372, 0.33083135, 0.30058914, 0.25162557,\n",
              "       0.24953088, 0.23958106, 0.23604625, 0.23264237, 0.2292385 ,\n",
              "       0.22635828, 0.2271438 , 0.2293694 , 0.2271438 , 0.22766747,\n",
              "       0.23473707, 0.24324678, 0.2939123 , 0.33109316, 0.4010037 ,\n",
              "       0.41566658, 0.3804495 , 0.41723764, 0.42260528, 0.4028366 ,\n",
              "       0.3693214 , 0.35662228, 0.29875627, 0.27126336, 0.25005454,\n",
              "       0.22884575, 0.22033603, 0.22662012, 0.22190705, 0.21981235,\n",
              "       0.22151428, 0.21981235, 0.21680121, 0.21549204, 0.22491819,\n",
              "       0.23120227, 0.26222998, 0.28461707, 0.32101244, 0.35112372,\n",
              "       0.3403884 , 0.34143573, 0.3369845 , 0.34706524, 0.34300676,\n",
              "       0.32834387, 0.28082043, 0.24769801, 0.24036658, 0.23185687,\n",
              "       0.23290421, 0.23382065, 0.22177613, 0.22518001, 0.22164522,\n",
              "       0.22059786, 0.21981235, 0.22046694, 0.22635828, 0.23224962,\n",
              "       0.2757146 , 0.27833298, 0.27558368, 0.34353042, 0.35675323,\n",
              "       0.37167796, 0.3437923 , 0.34758893, 0.32101247, 0.29626882,\n",
              "       0.2554222 , 0.22609644, 0.22452542, 0.22085969, 0.223609  ,\n",
              "       0.23107135, 0.22897665, 0.23094043, 0.23133318, 0.23028585,\n",
              "       0.23670085, 0.2384028 , 0.23814094, 0.23801003, 0.22976217,\n",
              "       0.22452542, 0.21300457, 0.20331661, 0.19441414, 0.18590443,\n",
              "       0.19847262, 0.20030548, 0.21287367, 0.21077897, 0.21509929,\n",
              "       0.21902685, 0.22884572], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWHigle8c76z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "396853ab-a35d-43e5-c1e9-df4c32ccc78b"
      },
      "source": [
        "EC_mean_test = (np.sum(Label_test_data[0]['y'])+np.sum(Label_test_data[1]['y'])) / (len(Label_test_data[0]['y'])+len(Label_test_data[1]['y']))\n",
        "print(EC_mean_test)\n",
        "print(EC_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59.98853926651306\n",
            "32.58286671659921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOd0xgJx4rxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e4bd40-604e-4d08-ef0c-54e457ef6390"
      },
      "source": [
        "BATCH_SPEC = collections.OrderedDict(x=tf.TensorSpec(shape=[None,6], dtype=tf.float32), y=tf.TensorSpec(shape=[None], dtype=tf.float32))\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "\n",
        "str(BATCH_TYPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<x=float32[?,6],y=float32[?]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKcWOEbhhPaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53d917d2-0d21-4e8a-a02d-2fa20ee5a8f6"
      },
      "source": [
        "MODEL_SPEC = collections.OrderedDict(weights1=tf.TensorSpec(shape=[6,5], dtype=tf.float32),\n",
        "                                     weights2=tf.TensorSpec(shape=[5,5], dtype=tf.float32),\n",
        "                                     weights3=tf.TensorSpec(shape=[5,1], dtype=tf.float32),\n",
        "                                     bias1=tf.TensorSpec(shape=[5], dtype=tf.float32),\n",
        "                                     bias2=tf.TensorSpec(shape=[5], dtype=tf.float32),\n",
        "                                     bias3=tf.TensorSpec(shape=[1], dtype=tf.float32))\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hdy-uMr5Hl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45df809d-6d38-4279-c708-bf4e867f3f59"
      },
      "source": [
        "MODEL_SPEC = collections.OrderedDict(weights1=tf.TensorSpec(shape=[6,5], dtype=tf.float32),\n",
        "                                     weights2=tf.TensorSpec(shape=[5,5], dtype=tf.float32),\n",
        "                                     weights3=tf.TensorSpec(shape=[5,5], dtype=tf.float32),\n",
        "                                     weights4=tf.TensorSpec(shape=[5,1], dtype=tf.float32),\n",
        "                                     bias1=tf.TensorSpec(shape=[5], dtype=tf.float32),\n",
        "                                     bias2=tf.TensorSpec(shape=[5], dtype=tf.float32),\n",
        "                                     bias3=tf.TensorSpec(shape=[5], dtype=tf.float32),\n",
        "                                     bias4=tf.TensorSpec(shape=[1], dtype=tf.float32))\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,5],weights4=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[5],bias4=float32[1]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYJfUODfhdZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n",
        "# be later called from within another tf.function. Necessary because a\n",
        "# @tf.function  decorated method cannot invoke a @tff.tf_computation.\n",
        "\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  y1 = tf.nn.relu(tf.matmul(batch['x'],model['weights1']) + model['bias1'])\n",
        "  y2 = tf.nn.relu(tf.matmul(y1,model['weights2']) + model['bias2'])\n",
        "  predicted_y = tf.matmul(y2,model['weights3']) + model['bias3']\n",
        "  return tf.reduce_mean(tf.square(batch['y'] - predicted_y))\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Npq9315Nx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n",
        "# be later called from within another tf.function. Necessary because a\n",
        "# @tf.function  decorated method cannot invoke a @tff.tf_computation.\n",
        "\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  y1 = tf.nn.relu(tf.matmul(batch['x'],model['weights1']) + model['bias1'])\n",
        "  y2 = tf.nn.relu(tf.matmul(y1,model['weights2']) + model['bias2'])\n",
        "  y3 = tf.nn.relu(tf.matmul(y2,model['weights3']) + model['bias3'])\n",
        "  predicted_y = tf.matmul(y3,model['weights4']) + model['bias4']\n",
        "  return tf.reduce_mean(tf.square(batch['y'] - predicted_y))\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14vQc9A45WBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7f452f9-48d7-41c7-b4ee-6eae4a86d3b5"
      },
      "source": [
        "str(batch_loss.type_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>,<x=float32[?,6],y=float32[?]>> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7nJZkz1hyv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def forward(model, batch):\n",
        "  y1 = tf.nn.relu(tf.matmul(batch['x'],model['weights1']) + model['bias1'])\n",
        "  y2 = tf.nn.relu(tf.matmul(y1,model['weights2']) + model['bias2'])\n",
        "  predicted_y = tf.matmul(y2,model['weights3']) + model['bias3']\n",
        "  return predicted_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs21yHKih2F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def forward(model, batch):\n",
        "  y1 = tf.nn.relu(tf.matmul(batch['x'],model['weights1']) + model['bias1'])\n",
        "  y2 = tf.nn.relu(tf.matmul(y1,model['weights2']) + model['bias2'])\n",
        "  y3 = tf.nn.relu(tf.matmul(y2,model['weights3']) + model['bias3'])\n",
        "  predicted_y = tf.matmul(y3,model['weights4']) + model['bias4']\n",
        "  return predicted_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uor-bcj9xQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e6b78f1c-7e75-4a78-f59d-4abecb3eefaa"
      },
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def Metrics_CVRMSE(model, batch):\n",
        "  prediction = forward(model, batch)\n",
        "  return (tf.sqrt(tf.reduce_mean(tf.square(batch['y'] - prediction))) / tf.reduce_mean(batch['y'])) * (1-EC_min/(tf.reduce_mean(batch['y'])*(EC_max-EC_min)+EC_min))\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def Metrics_RMSE(model, batch):\n",
        "  prediction = forward(model, batch)\n",
        "  return tf.sqrt(tf.reduce_mean(tf.square(batch['y'] - prediction))) * (EC_max-EC_min)\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def Metrics_MAE(model, batch):\n",
        "  prediction = forward(model, batch)\n",
        "  return tf.reduce_mean(tf.abs(batch['y'] - prediction)) * (EC_max-EC_min)\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def Metrics_MAPE(model, batch):\n",
        "  prediction = forward(model, batch)\n",
        "  return tf.reduce_mean(tf.abs(batch['y'] - prediction) / (batch['y']+EC_min/(EC_max-EC_min)))\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def Metrics_R2(model, batch):\n",
        "  prediction = forward(model, batch)\n",
        "  return 1 - tf.reduce_sum(tf.square(batch['y'] - prediction)) / tf.reduce_sum(tf.square(batch['y'] - tf.reduce_mean(batch['y'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function forward at 0x7f2ceb60f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function forward at 0x7f2ceb60f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function forward at 0x7f2ceb60f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function forward at 0x7f2ceb60f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function forward at 0x7f2ceb60f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vvN4XBiB0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccff0e34-ed48-4ea7-e61d-72cb9439e200"
      },
      "source": [
        "initial_model = collections.OrderedDict(weights1=np.zeros(shape=[6,5], dtype=np.float32),\n",
        "                                     weights2=np.zeros(shape=[5,5], dtype=np.float32),\n",
        "                                     weights3=np.zeros(shape=[5,1], dtype=np.float32),\n",
        "                                     bias1=np.zeros(shape=[5], dtype=np.float32),\n",
        "                                     bias2=np.zeros(shape=[5], dtype=np.float32),\n",
        "                                     bias3=np.zeros(shape=[1], dtype=np.float32))\n",
        "\n",
        "sample_batch = federated_train_data[4][-2]\n",
        "\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0629788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzNQuqVQ5cD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_model = collections.OrderedDict(weights1=np.zeros(shape=[6,5], dtype=np.float32),\n",
        "                                     weights2=np.zeros(shape=[5,5], dtype=np.float32),\n",
        "                                     weights3=np.zeros(shape=[5,5], dtype=np.float32),\n",
        "                                     weights4=np.zeros(shape=[5,1], dtype=np.float32),\n",
        "                                     bias1=np.zeros(shape=[5], dtype=np.float32),\n",
        "                                     bias2=np.zeros(shape=[5], dtype=np.float32),\n",
        "                                     bias3=np.zeros(shape=[5], dtype=np.float32),\n",
        "                                     bias4=np.zeros(shape=[1], dtype=np.float32))\n",
        "\n",
        "sample_batch = federated_train_data[4][-2]\n",
        "\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST9-hoQVdiKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3df4308a-784b-4687-b29d-860854b24d95"
      },
      "source": [
        "Metrics_CVRMSE(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9921009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYLtghAx-j-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce34b37e-5f6e-42ef-d4fc-68efa6363c88"
      },
      "source": [
        "Metrics_RMSE(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.922092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF1Ts3dU-mtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "961cb2cd-ad7a-4845-f334-b886647ccd0d"
      },
      "source": [
        "Metrics_MAE(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.67863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrlzAQH--qjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cc4d5b9-ba2f-41a4-e5d4-9cb5892733eb"
      },
      "source": [
        "Metrics_MAPE(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9646735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP4UbjZW-vgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba93b5a7-3954-4312-cf0f-c44aa16fe4c9"
      },
      "source": [
        "Metrics_R2(initial_model, sample_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9760.624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UZ6G9Tn5jLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  # Define a group of model variables and set them to `initial_model`. Must\n",
        "  # be defined outside the @tf.function.\n",
        "  model_vars = collections.OrderedDict([(name, tf.Variable(name=name, initial_value=value)) for name, value in initial_model.items()])\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from `batch_loss`.\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
        "    return model_vars\n",
        "\n",
        "  return _train_on_batch(model_vars, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzTbvD0f6P4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7f524b6d-c5fd-4bbf-c878-bcbcc4150d26"
      },
      "source": [
        "str(batch_train.type_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>,<x=float32[?,6],y=float32[?]>,float32> -> <weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7joW7oB6VEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = initial_model\n",
        "losses = []\n",
        "CVRMSE = []\n",
        "for _ in range(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  losses.append(batch_loss(model, sample_batch))\n",
        "  CVRMSE.append(Metrics_CVRMSE(model, sample_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IDB68Ao6m0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dea0873-336b-43fe-a7ab-c24cca13e911"
      },
      "source": [
        "losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.041467734, 0.02770063, 0.018889714, 0.013250715, 0.009641752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYTEaAYf_Wqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85819d13-a246-4cc1-8cd6-c08f5482b9e7"
      },
      "source": [
        "CVRMSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.80503327, 0.6579661, 0.5433396, 0.45507017, 0.38818312]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHegTHY06uAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "\n",
        "  # Mapping function to apply to each batch.\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHi44KFt6zv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "64e03017-2ca9-4a4b-dafc-6650e4406d7c"
      },
      "source": [
        "str(local_train.type_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>,float32,<x=float32[?,6],y=float32[?]>*> -> <weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxNQjnbfGeea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.tf_computation(tf.float32, tf.float32)\n",
        "def division(a, b):\n",
        "  return a / b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd5TDkkmJDmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.tf_computation(tf.float32, tf.float32)\n",
        "def division(a, b):\n",
        "  return tf.divide(a, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1rhQmR2G7vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.tf_computation()\n",
        "def get_one():\n",
        "  return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXrUtB2T65LE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n",
        "  return tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE), all_batches))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRidTSsTm5NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval_CVRMSE(model, all_batches):\n",
        "  sum_of_sequence = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: Metrics_CVRMSE(model, b), BATCH_TYPE), all_batches))\n",
        "  num = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: 1.0, BATCH_TYPE), all_batches))\n",
        "  return division(sum_of_sequence, num)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval_RMSE(model, all_batches):\n",
        "  sum_of_sequence = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: Metrics_RMSE(model, b), BATCH_TYPE), all_batches))\n",
        "  num = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: 1.0, BATCH_TYPE), all_batches))\n",
        "  return division(sum_of_sequence, num)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval_MAE(model, all_batches):\n",
        "  sum_of_sequence = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: Metrics_MAE(model, b), BATCH_TYPE), all_batches))\n",
        "  num = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: 1.0, BATCH_TYPE), all_batches))\n",
        "  return division(sum_of_sequence, num)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval_MAPE(model, all_batches):\n",
        "  sum_of_sequence = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: Metrics_MAPE(model, b), BATCH_TYPE), all_batches))\n",
        "  num = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: 1.0, BATCH_TYPE), all_batches))\n",
        "  return division(sum_of_sequence, num)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval_R2(model, all_batches):\n",
        "  sum_of_sequence = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: Metrics_R2(model, b), BATCH_TYPE), all_batches))\n",
        "  num = tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: 1.0, BATCH_TYPE), all_batches))\n",
        "  return division(sum_of_sequence, num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwnqlyeJ7HKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62006e2e-582a-415f-f51c-832e3a7428f5"
      },
      "source": [
        "str(local_eval_CVRMSE.type_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights1=float32[6,5],weights2=float32[5,5],weights3=float32[5,1],bias1=float32[5],bias2=float32[5],bias3=float32[1]>,<x=float32[?,6],y=float32[?]>*> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouiKOL9Y62QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxFnH1_H7N46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ae24117-7fe3-4db9-bffe-136e2530b59d"
      },
      "source": [
        "print('initial_model loss =', local_eval(initial_model, federated_train_data[4]))\n",
        "print('locally_trained_model loss =', local_eval(locally_trained_model, federated_train_data[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss = 0.49093497\n",
            "locally_trained_model loss = 0.029914347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWZqyeYjNZ7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9c97e430-eeb3-4ade-9d24-6e9625aed287"
      },
      "source": [
        "print('initial_model CVRMSE =', local_eval_CVRMSE(initial_model, federated_train_data[4]))\n",
        "print('locally_trained_model RMSE =', local_eval_RMSE(locally_trained_model, federated_train_data[4]))\n",
        "print('locally_trained_model CVRMSE =', local_eval_CVRMSE(locally_trained_model, federated_train_data[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model CVRMSE = 0.983731\n",
            "locally_trained_model RMSE = 11.177309\n",
            "locally_trained_model CVRMSE = 0.22980188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pcmKOng7ZSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d8e63880-24f7-4cac-dbdc-e28fa9e2a1ba"
      },
      "source": [
        "print('initial_model loss =', local_eval_CVRMSE(initial_model, federated_train_data[0]))\n",
        "print('locally_trained_model loss =', local_eval_CVRMSE(locally_trained_model, federated_train_data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss = 0.827339\n",
            "locally_trained_model loss = 3.9903874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivGsomq57fCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymyNYUpQ7hPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuB0z60BXFa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval_CVRMSE(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval_CVRMSE, [tff.federated_broadcast(model), data]))\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval_RMSE(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval_RMSE, [tff.federated_broadcast(model), data]))\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval_MAE(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval_MAE, [tff.federated_broadcast(model), data]))\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval_MAPE(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval_MAPE, [tff.federated_broadcast(model), data]))\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval_R2(model, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_eval_R2, [tff.federated_broadcast(model), data]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvPiC0fe8hET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ffc09586-033a-4ce6-81c6-54d9e3bee526"
      },
      "source": [
        "print('initial_model loss =', federated_eval(initial_model, federated_train_data))\n",
        "print('locally_trained_model loss =', federated_eval(locally_trained_model, federated_train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss = 0.3311762\n",
            "locally_trained_model loss = 0.20935066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSn4ePsrKbQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0aa8b680-acdd-40bd-93c1-d2bf01c9147c"
      },
      "source": [
        "print('initial_model CVRMSE =', federated_eval_CVRMSE(initial_model, federated_train_data))\n",
        "print('locally_trained_model CVRMSE =', federated_eval_CVRMSE(locally_trained_model, federated_train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model CVRMSE = 0.96025115\n",
            "locally_trained_model CVRMSE = 2.2337132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euoilORn9Prd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  return tff.federated_mean(tff.federated_map(local_train, [tff.federated_broadcast(model), tff.federated_broadcast(learning_rate), data]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuufmbidmw4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_model = collections.OrderedDict(weights1=np.random.rand(6,5).astype(np.float32),\n",
        "                    weights2=np.random.rand(5,5).astype(np.float32),\n",
        "                    weights3=np.random.rand(5,1).astype(np.float32),\n",
        "                    bias1=np.random.rand(5).astype(np.float32),\n",
        "                    bias2=np.random.rand(5).astype(np.float32),\n",
        "                    bias3=np.random.rand(1).astype(np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm-H2zfD-RP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1c9fb761-da5e-4f5f-b658-e7ca6053613a"
      },
      "source": [
        "fed_model = initial_model\n",
        "learning_rate = 0.1\n",
        "loss = []\n",
        "for round_num in range(50):\n",
        "  fed_model = federated_train(fed_model, learning_rate, federated_train_data)\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  loss_ = federated_eval(fed_model, federated_train_data)\n",
        "  RMSE = federated_eval_RMSE(fed_model, federated_train_data)\n",
        "  CVRMSE = federated_eval_CVRMSE(fed_model, federated_train_data)\n",
        "  loss.append(loss_) \n",
        "  if len(loss) > 1:\n",
        "    if ((loss[-2]-loss[-1]) / loss[-2] < 0.0001):\n",
        "      print('Train process is done')\n",
        "      break\n",
        "  print('round {}, loss={}, RMSE={}, CVRMSE={}'.format(round_num, loss_, RMSE, CVRMSE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 0, loss=3.5958471298217773, RMSE=125.65668487548828, CVRMSE=7.9549713134765625\n",
            "round 1, loss=0.3102833330631256, RMSE=27.470705032348633, CVRMSE=0.8431023955345154\n",
            "round 2, loss=0.18031781911849976, RMSE=22.725921630859375, CVRMSE=1.1795583963394165\n",
            "round 3, loss=0.1737377643585205, RMSE=23.714635848999023, CVRMSE=1.412951111793518\n",
            "round 4, loss=0.173425555229187, RMSE=24.03350067138672, CVRMSE=1.4761743545532227\n",
            "Train process is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2k7LkpjruHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a8d90582-d78d-4b03-8a7e-674f3d14f19a"
      },
      "source": [
        "print('initial_model train CVRMSE =', federated_eval_CVRMSE(initial_model, federated_train_data))\n",
        "print('trained_model train CVRMSE =', federated_eval_CVRMSE(fed_model, federated_train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model train CVRMSE = 223.89607\n",
            "trained_model train CVRMSE = 1.493701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG6fJXw_bYbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0722fdca-f4fe-4d5b-eeaa-92636b8feedf"
      },
      "source": [
        "print('initial_model test RMSE =', local_eval_RMSE(initial_model, local_test_data))\n",
        "print('trained_model test RMSE =', local_eval_RMSE(fed_model, local_test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test RMSE = 3072.248\n",
            "trained_model test RMSE = 31.971203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1R64R-NunoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6c46b9a-1aac-4b7c-d711-0321126c8383"
      },
      "source": [
        "print('trained_model test CVRMSE =', local_eval_RMSE(fed_model, local_test_data)/EC_mean_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trained_model test CVRMSE = 0.5329551817940137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dp8RdBL-ndy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8de5a649-aec9-40ff-9c06-62cc17e91ecd"
      },
      "source": [
        "print('initial_model test CVRMSE =', local_eval_CVRMSE(initial_model, local_test_data))\n",
        "print('trained_model test CVRMSE =', local_eval_CVRMSE(fed_model, local_test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test CVRMSE = 50.99831\n",
            "trained_model test CVRMSE = 0.5306189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuRbWu7sHMxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "f7e2b63c-41a4-47e5-a559-0f012eff5f5f"
      },
      "source": [
        "local_model = fed_model\n",
        "learning_rate = 0.1\n",
        "loss = []\n",
        "for round_num in range(50):\n",
        "  local_model = local_train(local_model, learning_rate, local_train_data)\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  loss_ = local_eval(local_model, local_train_data)\n",
        "  RMSE = local_eval_RMSE(local_model, local_train_data)\n",
        "  CVRMSE = local_eval_CVRMSE(local_model, local_train_data)\n",
        "  loss.append(loss_) \n",
        "  if len(loss) > 1:\n",
        "    if ((loss[-2]-loss[-1]) / loss[-2] < 0.0001):\n",
        "      print('Train process is done')\n",
        "      break\n",
        "  print('round {}, loss={}, RMSE={}, CVRMSE={}'.format(round_num, loss_, RMSE, CVRMSE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 0, loss=0.023509668186306953, RMSE=20.703439712524414, CVRMSE=0.3473283648490906\n",
            "round 1, loss=0.011748472228646278, RMSE=14.635294914245605, CVRMSE=0.24552641808986664\n",
            "round 2, loss=0.006828448735177517, RMSE=11.1571683883667, CVRMSE=0.1871756911277771\n",
            "round 3, loss=0.004589683376252651, RMSE=9.146533012390137, CVRMSE=0.15344424545764923\n",
            "round 4, loss=0.0034926123917102814, RMSE=7.9782562255859375, CVRMSE=0.13384458422660828\n",
            "round 5, loss=0.002918635029345751, RMSE=7.2927751541137695, CVRMSE=0.12234457582235336\n",
            "round 6, loss=0.0026004172395914793, RMSE=6.883371829986572, CVRMSE=0.11547618359327316\n",
            "round 7, loss=0.0024146903306245804, RMSE=6.632757663726807, CVRMSE=0.11127173900604248\n",
            "round 8, loss=0.0023012273013591766, RMSE=6.474887847900391, CVRMSE=0.10862323641777039\n",
            "round 9, loss=0.002229036297649145, RMSE=6.372414588928223, CVRMSE=0.10690408945083618\n",
            "round 10, loss=0.002181412884965539, RMSE=6.303908348083496, CVRMSE=0.1057547926902771\n",
            "round 11, loss=0.0021489672362804413, RMSE=6.256810188293457, CVRMSE=0.10496465861797333\n",
            "round 12, loss=0.0021262140944600105, RMSE=6.22357177734375, CVRMSE=0.10440704971551895\n",
            "round 13, loss=0.0021098428405821323, RMSE=6.199549198150635, CVRMSE=0.10400402545928955\n",
            "round 14, loss=0.002097789663821459, RMSE=6.181804656982422, CVRMSE=0.10370634496212006\n",
            "round 15, loss=0.0020887325517833233, RMSE=6.168438911437988, CVRMSE=0.10348211228847504\n",
            "round 16, loss=0.0020817983895540237, RMSE=6.1581878662109375, CVRMSE=0.10331013798713684\n",
            "round 17, loss=0.0020764009095728397, RMSE=6.1501970291137695, CVRMSE=0.10317609459161758\n",
            "round 18, loss=0.0020721382461488247, RMSE=6.1438798904418945, CVRMSE=0.10307011008262634\n",
            "round 19, loss=0.0020687258802354336, RMSE=6.138818740844727, CVRMSE=0.1029852032661438\n",
            "round 20, loss=0.0020659619476646185, RMSE=6.134716033935547, CVRMSE=0.10291637480258942\n",
            "round 21, loss=0.0020636990666389465, RMSE=6.1313557624816895, CVRMSE=0.10286000370979309\n",
            "round 22, loss=0.0020618289709091187, RMSE=6.12857723236084, CVRMSE=0.10281339287757874\n",
            "round 23, loss=0.0020602697040885687, RMSE=6.126260280609131, CVRMSE=0.10277451574802399\n",
            "round 24, loss=0.0020589600317180157, RMSE=6.1243133544921875, CVRMSE=0.10274185240268707\n",
            "round 25, loss=0.0020578517578542233, RMSE=6.1226654052734375, CVRMSE=0.10271421074867249\n",
            "round 26, loss=0.0020569078624248505, RMSE=6.1212615966796875, CVRMSE=0.1026906669139862\n",
            "round 27, loss=0.002056100405752659, RMSE=6.120060443878174, CVRMSE=0.10267052054405212\n",
            "round 28, loss=0.0020554051734507084, RMSE=6.119026184082031, CVRMSE=0.10265316814184189\n",
            "round 29, loss=0.0020548044703900814, RMSE=6.118132591247559, CVRMSE=0.10263817757368088\n",
            "round 30, loss=0.0020542836282402277, RMSE=6.11735725402832, CVRMSE=0.10262517631053925\n",
            "round 31, loss=0.002053829375654459, RMSE=6.116681098937988, CVRMSE=0.10261382907629013\n",
            "round 32, loss=0.002053432399407029, RMSE=6.116090774536133, CVRMSE=0.10260392725467682\n",
            "round 33, loss=0.0020530850160866976, RMSE=6.115573883056641, CVRMSE=0.1025952473282814\n",
            "round 34, loss=0.002052778610959649, RMSE=6.115118026733398, CVRMSE=0.10258759558200836\n",
            "round 35, loss=0.002052509691566229, RMSE=6.114717483520508, CVRMSE=0.10258088260889053\n",
            "round 36, loss=0.0020522731356322765, RMSE=6.114365577697754, CVRMSE=0.10257497429847717\n",
            "round 37, loss=0.0020520624238997698, RMSE=6.114051818847656, CVRMSE=0.10256971418857574\n",
            "Train process is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_htwSeFasdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "168800c7-32d2-43f2-8767-5bc8ae2c29ed"
      },
      "source": [
        "print('initial_model test RMSE =', local_eval_RMSE(initial_model, local_test_data))\n",
        "print('local_model test RMSE =', local_eval_RMSE(local_model, local_test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test RMSE = 3072.248\n",
            "local_model test RMSE = 5.2883606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5o4lXR8Dy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96f3451e-88d0-4f3e-a5ab-f6b55d596a0e"
      },
      "source": [
        "print('local_model test CVRMSE =', local_eval_RMSE(local_model, local_test_data)/EC_mean_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "local_model test CVRMSE = 0.0881561821702034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAut4kt0XZd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b0f5bbcd-41f7-43d7-cd1a-2a5056f21283"
      },
      "source": [
        "print('initial_model test CVRMSE =', local_eval_CVRMSE(initial_model, local_test_data))\n",
        "print('local_model test CVRMSE =', local_eval_CVRMSE(local_model, local_test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test CVRMSE = 50.99831\n",
            "local_model test CVRMSE = 0.087783575\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}